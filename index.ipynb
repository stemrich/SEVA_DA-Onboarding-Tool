{
 "cells": [
  {
   "source": [
    "# Data Analytics Onboarding Tool\n",
    "\n",
    "Diesem Python-Notebook wurde entwickelt um\n",
    "\n",
    "- eine weitgehend automatische deskriptive Analyse von Datensätzen zu ermöglichen\n",
    "- die Potentiale von code-basierter Analyse zu zeigen\n",
    "- einen Ausblick auf die Möglichkeiten von Machine-Learning zu geben\n",
    "\n",
    "Beispielhaft wird hier der Gemeindedatensatz aus der DDJ-Lehrveranstaltung der FH Joanneum Graz verwendet.\n",
    "\n",
    "___\n",
    "\n",
    "### Hinweise zur Benützung des Notebooks\n",
    "\n",
    "* Das Tools selbst ist interaktiv und somit ist es Möglich den Programmiercode an jeder Stelle zu verändern und an persönliche Bedürfnisse anzupassen.\n",
    "\n",
    "* Das originale Notebook wird dabei nicht überschrieben. Änderungen sind daher unbedenklich - das Original kann jederzeit wiederhergestellt werden.\n",
    "\n",
    "* Bei längerer Inaktivität wird deine Session beendet. Alle Änderungen gehen dann auch verloren. Du kannst aber deine Änderungen im Browser speichern und später wieder laden (mit den zwei Wolken-Icons).\n",
    "![Screenshot Zelle ausführen](screenshots/save-restore.jpg)\n",
    "\n",
    "* Das Notebook besteht aus separaten Zellen.\n",
    "\n",
    "* Die aktive Zelle ist durch einen blauen vertikalen Balken am linken Rand gekennzeichnet.\n",
    "\n",
    "* Es wird unterschieden zwischen Text- und Code-Zellen.\n",
    "\n",
    "* In Text-Zellen, so wie diese, finden sich Erklärungen und Anleitungen.\n",
    "\n",
    "* In Code-Zellen steht der ausführbare Programmiercode.\n",
    "\n",
    "* Du kannst mit “Enter” oder Doppelklick die aktive Zelle bearbeiten, also den Text oder Code in der Zelle ändern. Dann ändert sich der vertikale Balken links von blau auf grün.\n",
    "\n",
    "* In Code-Zellen dient die Raute **#** zum Auskommentieren. Solche Zeilen können entweder Erklärungen sein, oder dazu dienen Optionen im Code auszuprobieren (indem eine Zeile auskommentiert und/oder eine andere aktiviert wird).\n",
    "\n",
    "* Mit \"Strg+Enter\" oder dem Button \"Run\" wird die aktive Zelle ausgeführt und danach die nächste Zelle aktiviert.\n",
    "![Screenshot Zelle ausführen](screenshots/da-firstview2.jpg)\n",
    "\n",
    "* Handelt es sich um eine Text-Zelle (wie diese hier), geschieht dabei weiter nichts.\n",
    "\n",
    "* Wenn es eine Code-Zelle ist, dann wird der Code der Zelle ausgeführt und ein entsprechendes Ergebnis ausgegeben. Eine Code-Zelle ist daran erkennbar, dass die Formatierung deutlich anders aussieht und links von ihr dieses Symbol zu finden ist:\n",
    "> In \\[#\\]:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Datenimport\n",
    "\n",
    "Im ersten Schritt werden die notwendigen Libraries, sowie der Datensatz selbst geladen.\n",
    "\n",
    "* **pandas** ist eine sehr mächtige Library die speziell für Datenanalyse entwickelt wurde. Die Library verfügt auch über eine Vielzahl an Datenimport (und -Export) Befehlen.\n",
    "* **seaborn** ist eine Library für die statistische Datenvisualisierung.\n",
    "\n",
    "**import pandas as pd** importiert die gesamte *pandas*-Library und stellt sie unter dem Kürzel *pd* zur Verfügung. Somit können im Folgenden befehle aus der Library mit *pd.gewuenschter_befehl* abgerufen werden. Wie etwa der Befehl *read_csv* der den Datenimport aus CSV-Dateien erledigt.\n",
    "\n",
    "___\n",
    "\n",
    "### Coding\n",
    "Wenn du Gefallen am Programmieren findest, dir aber weitere Befehle \"fehlen\" (was auch erfahrenen ProgrammiererInnen regelmäßig passiert), dann sind das einige der ersten Anlaufstationen für Hilfe:\n",
    "\n",
    "* Eine Sammlung von [grundlegenden Python Befehlen ist hier zu finden](https://www.pythoncheatsheet.org/)\n",
    "* Für Python Libraries (aber auch jene anderer Programmiersprachen) gibt es eine Vielzahl an *Cheat Sheets*. Diese beinhalten eine Übersicht über die gängigsten Befehle der Library.\n",
    "* Ein Cheat-Sheet für die Pandas Library [findest du hier](https://intellipaat.com/mediaFiles/2018/12/Python-Pandas-Cheat-Sheet.png)\n",
    "* Einfach danach suchen (via Quant, DuckDuckGoGo, Google, ...). Bei Befehlen von Libraries diese immer mit angeben. Z.B.: *python pandas show row with maximum*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Import kompletter Librarie\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Import einer einzigen Funktion aus einer Library\n",
    "from pandas_profiling import ProfileReport\n",
    "from profilehilfe import profile_helfen # Erweiterte DA-Hilfestellung\n",
    "\n",
    "# Import des Gemeindedatensatzes mit Pandas \n",
    "# die Option sep=\";\" gibt das Trennzeichen für die Spalten an (separator)\n",
    "gemeindedaten = pd.read_csv('alle_gemeinden.csv', sep=';')\n",
    "\n",
    "# Ausgabe der ersten Zeilen zur Kontrolle\n",
    "gemeindedaten.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Was hier auffällt ist, dass im CSV-File Spalten sind in denen ein \",\" als Dezimaltrennzeichen verwendet wird, und solche in denen ein \".\" verwendet wird. Dieses Problem ist ein extrem gängiges Problem, welches auch bei der Verwendung von Excel (oder anderen Tabellenkalkulationsprogrammen) berücksichtig werden muss.\n",
    "\n",
    "Durch die unterschiedlichen Dezimaltennzeichen sind die Daten nicht vernünftig verarbeitbar, da sie falsch eingelesen werden: Der Befehl *.dtypes* wird auf unseren Datensatz angewandt und zeigt uns, als was für Daten die einzelnen Spalten erkannt wurden."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gemeindedaten.dtypes)"
   ]
  },
  {
   "source": [
    "Wie man sieht, sind die Spalten \"Name\", \"Alter\", \"Grundstückspreise\" und \"Anzahl der Kinder\" als *object* kodiert - also keine Zahlen (float oder integer).\n",
    "\n",
    "Um dieses Problem zu lösen werden wir die Dezimaltrennzeichen im CSV-File vereinheitlichen (auf \".\"). Dazu gehen wir wie folgt vor:\n",
    "\n",
    "1. Einlesen des CSV\n",
    "2. Umwandeln aller \",\" die eventuell als Text vorhanden sind durch eine sehr unwahrscheinliche Zeichenkombination (##@#!)\n",
    "3. Ersetzen aller vorhandener \",\" durch \".\"\n",
    "4. Rückumwandlung der Beistriche"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Öffnen des CSV-Files mit den Daten\n",
    "with open(\"alle_gemeinden.csv\") as datei:\n",
    "    content = datei.read()\n",
    "\n",
    "# Vereinheitlichen der Dezimaltrennzeichen\n",
    "content = content.replace('\",\"','##@#!')    # Umwandlung von notwendigen Beistriche in Text\n",
    "content = content.replace(',','.')          # Ersetzen aller (verbliebenen) Kommas durch Punkt\n",
    "content = content.replace('##@#!','\",\"')    # Rückumwandlung der Text-Beistriche\n",
    "\n",
    "# Speichern des (neuen) CSV-Files\n",
    "with open(\"gemeinden.csv\", \"w\") as datei:\n",
    "    content = datei.write(content)\n",
    "\n",
    "# Import des CSV-Files mithilfe des Pandas-Library Befeheles \"read_csv\", welcher\n",
    "# einen sogenannten \"Pandas DataFrame\" anlegt. In diesem Format wird die \n",
    "# Variable \"gemeindedaten\" gespeichert.\n",
    "gemeindedaten = pd.read_csv('gemeinden.csv', sep=';', na_values=[\"-\"])\n",
    "\n",
    "# Kontrolle anhand der ersten Zeilen\n",
    "gemeindedaten.head()"
   ]
  },
  {
   "source": [
    "Nun sind alle Spalten korrekt kodiert, was man sich mit *gemeindedaten.dtypes* auch noch ansehen kann (Kommentar vor dem Befehl entfernen).\n",
    "\n",
    "Bleibt noch zu klären, ob alle Daten eingelesen wurden. Mithilfe von *shape* wird die Dimension des Datensatzes ausgegeben."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wiederholte Kontrolle des Datensatzes:\n",
    "# kommentiere die Folgende Zeile aus um sie ausführen zu können. \n",
    "\n",
    "#gemeindedaten.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfe ob Datensatz vollständig ist (auskommentieren)\n",
    "# Ausgabe erfolgt im Format \n",
    "# (Anzahl Zeilen, Anzahl Spalten)\n",
    "\n",
    "#gemeindedaten.shape"
   ]
  },
  {
   "source": [
    "Ist der Datensatz vollständig?\n",
    "Laut [Wikipedia](https://de.wikipedia.org/wiki/Gemeinde_(%C3%96sterreich)) gibt es in Österreich 2095 Gemeinden (Stand 1. Jänner 2020)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Deskriptive Analyse\n",
    "\n",
    "Der Datensatz soll nun einer ersten Analyse unterzogen werden. Dabei stellt sich die Frage nach der Aussagekraft bei der Gegenüberstellung der einzelnen Gemeinden. Nachdem eine Großstadt mehr Einwohner hat, ist es auch naheliegend, dass sie mehr Ehepaare haben wird als ein kleines Bergdorf. Um die Gemeinden miteinander vergleichen zu können macht es daher für *Anzahl an Ehepaaren* Sinn die Variable in Relation zur Einwohnerzahl zu setzen.\n",
    "\n",
    "Das selbe trifft auch auf *Arbeitsstätten*, *Beschäftigte* und *Erbwerbstätige (15-64)* zu. Diese Spalten werden im Folgenden normiert.\n",
    "___\n",
    "\n",
    "## Normierung"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle eine Kopie des Datensatzes\n",
    "# (sicher ist sicher - so kann immer auf das Original zugegriffen werden ;)\n",
    "daten_normiert = gemeindedaten.copy()\n",
    "\n",
    "# Division der 4 Spalten/Variablen durch die Einwohneranzahl\n",
    "daten_normiert[\"Arbeitsstätten\"] = daten_normiert[\"Arbeitsstätten\"]/daten_normiert[\"Einwohner\"]\n",
    "daten_normiert[\"Beschäftigte\"] = daten_normiert[\"Beschäftigte\"]/daten_normiert[\"Einwohner\"]\n",
    "daten_normiert[\"Erbwerbstätige (15-64)\"] = daten_normiert[\"Erbwerbstätige (15-64)\"]/daten_normiert[\"Einwohner\"]\n",
    "daten_normiert[\"Anzahl an Ehepaaren\"] = daten_normiert[\"Anzahl an Ehepaaren\"]/daten_normiert[\"Einwohner\"]\n",
    "\n",
    "# Ausgabe zur Kontrolle\n",
    "daten_normiert.head()"
   ]
  },
  {
   "source": [
    "## Deskriptive Analyse\n",
    "\n",
    "Wir können den normierten Datensatz jetzt mit Pandas Profiling analysieren lassen.\n",
    "\n",
    "***Hinweis: Das kann bis zu einer Minute dauern!***\n",
    "___\n",
    "\n",
    "Der Report besteht aus 6 Kapiteln.\n",
    "\n",
    "1. *Overview*: Hier werden die Eckdaten angezeit und *Warnings* betreffend die einzelnen Variablen ausgegeben. *Reproduction* ist nicht wirklich relevant.\n",
    "2. *Variables* beinhaltet eine Analyse jeder einzelnen Variablen. Mit *Toggle details* kann jeweils noch ein vielfaches an Zusatzinformationen eingebledet werden.\n",
    "3. *Interactions* bietet die Möglichkeit je 2 Variablen gegeneinander anzuzeigen. Wir werden in einem nächsten Schritt noch eine zweite Möglichkeit dafür kennen lernen.\n",
    "4. *Correlations* berechnet statistische Korrelationsmaße für die Variablen zueinander. Mit *Toggle correlation description* kann man sich eine Beschreibung des jeweiligen Maßes anzeigen lassen.\n",
    "5. *Missing values* weist die Anzahl an fehlenden Werten je Variable aus\n",
    "6. *Sample* ist ein stichprobenartiger Einblick in den Beginn und das Ende unseses Datesatzes (analog zum obigen Befehl *daten_normiert.head()*)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiling-Analyse unseres Datensatzes\n",
    "profile = ProfileReport(daten_normiert, title='Pandas Profiling Report', explorative=True)\n",
    "\n",
    "# Darstellung der Ergebnisse\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "source": [
    "## Fragen und To-Dos\n",
    "\n",
    "Analysiere die Daten mithilfe des *Pandas Profiling Reports* und versuche dabei Fragen zu beantworten:\n",
    "\n",
    "1. Sind die Overview & Warnings für dich verständlich und hilfreich?\n",
    "2. Was bedeuten die Warnings? Sind sie relevant? Wenn ja/nein welche und warum (nicht)?\n",
    "3. Was könnten Gründe für die hohe Korrelation von Variablen sein?\n",
    "4. Gibt es bei den Variablen Probleme?\n",
    "5. Sind die Grafiken verständlich?\n",
    "\n",
    "Wenn du damit fertig bist, führe die folgende Funktion aus, welche dir weitere Hilfestellungen zum Report bietet."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erweiterte automatisierte Info zum Profiling-Report\n",
    "# Import der Funktion erfolgte am Notebook-Beginn.\n",
    "\n",
    "profile_helfen(profile)"
   ]
  },
  {
   "source": [
    "## Vertiefende Erklärungen\n",
    "\n",
    "Helfen dir diese weiterführenden Informationen zum Profiling Report? Bitte erkläre ...\n",
    "\n",
    "* welche dir (nicht) geholfen haben und warum (nicht), sowie\n",
    "* was du zusätzlich zu deiner ersten Analyse herausgefunden/entdeckt hast.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Ausreißer, Korrelation & Kausalität\n",
    "\n",
    "Das interessante bei Datensätze ist es die \"versteckte\" Information darin zu finden: Zusammenhänge und Muster. Und in weiterer Folge Erklärungen dafür. Im obigen Report haben wir dafür schon *Interactions* und *Correlations* gesehen. Eine weiter Möglichkeit sich einem Datensatz zu nähern bietet der Scatterplot. Genauer gesagt eine Technik die \"Small Multiples\" genannt wird und aus einer Vielzahl an Scatterplots besteht (auch Pairplot genannt).\n",
    "\n",
    "Für den Datensatz lassen wir uns so einen Plot erzeugen.\n",
    "\n",
    "***Hinweis: Das kann bis zu 90 Sekunden dauern!***\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot für visuelle Analyse\n",
    "\n",
    "# Auswahl der Variablen von Interesse\n",
    "# Der Gemeindenamen zB ist hier (als kategorische Variable) nicht sinnvoll\n",
    "# Du kannst die Auswahl nach belieben Ändern!\n",
    "features = [\"Einwohner\", \"Arbeitsstätten\", \"Beschäftigte\", \"Alter\", \"Einkommen\", \"Erbwerbstätige (15-64)\", \"Grundstückspreise\", \"Anzahl an Ehepaaren\", \"Anzahl der Kinder\"]\n",
    "\n",
    "# Erstellen des Plots mit den gewählten Features\n",
    "ft_plot = sns.pairplot(daten_normiert[features])"
   ]
  },
  {
   "source": [
    "Diese Art von Darstellung eignet sich sehr gut um Ausreißer und Zusammenhänge in den Daten zu erkennen.\n",
    "\n",
    "***Ausreißer***\n",
    "\n",
    "Von einem Ausreißer spricht man in der Statistik, wenn ein (Mess-)Wert nicht in eine erwartete Messreihe passt oder allgemein nicht den Erwartungen entspricht.\n",
    "\n",
    "Im Pairplot sind das Punkte die (weit) abseits der (zusammenhängenden) Punktewolken liegen. Ausreißer können unterschiedliche Erklärungen haben. Sie können sowohl auf Datenfehler zurückgehen, als auch völlig legitim sein. Die richtige Einordnung erfordert bei komplexen Daten in der Regel ExpertInnenwissen.\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "## Visuelle Analyse - Ausreißer\n",
    "\n",
    "Analysiere nun den Pairplot (s.a. Logbuch):\n",
    "\n",
    "1. Ist die Visualisierung für dich verständlich?\n",
    "2. Wo fallen dir Ausreißer auf?\n",
    "    * Sind diese in Ordnung?\n",
    "    * Was für Erklärung(en) gibt es dafür?\n",
    "\n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Visuelle Analyse - Zusammenhänge\n",
    "\n",
    "Wenn es in Daten Zusammenhänge gibt, dann kann man diese oft ebenfalls mithilfe von Scatterplots feststellen. Im obigen Beispiel haben wir den (anfangs) normierten Datensatz abgebildet, da sonst der Vergleich einzelner Gemeinden miteinander nicht wirklich aussagekräftig wäre.\n",
    "\n",
    "Um Zusammenhänge zwischen Variablen (Eigenschaften) zu zeigen, eignet sich der ursprüngliche Datensatz jedoch besser.\n",
    "\n",
    "**Aufgabenstellung (s.a. Logbuch):**\n",
    "\n",
    "Erstelle dir einen Pairplot für den Datensatz *gemeindedaten* mit den Variablen\n",
    "\n",
    "* Einwohner\n",
    "* Erbwerbstätige (15-64)\n",
    "* Anzahl an Ehepaaren\n",
    "* Anzahl der Kinder\n",
    "\n",
    "füge ihn als Screenshot ins Logbuch ein und beschreibe was dir dabei (im Gegensatz zum ersten Pairplot) auffällt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist eine Kopie des Befehls von oben als Platzhalter\n",
    "\n",
    "# Auswahl der Variablen von Interesse\n",
    "features = [\"Einwohner\", \"Arbeitsstätten\", \"Beschäftigte\", \"Alter\", \"Einkommen\", \"Erbwerbstätige (15-64)\", \"Grundstückspreise\", \"Anzahl an Ehepaaren\", \"Anzahl der Kinder\"]\n",
    "\n",
    "# Erstellen des Plots mit den gewählten Features\n",
    "ft_plot = sns.pairplot(daten_normiert[features])"
   ]
  },
  {
   "source": [
    "## Korrelation vs. Kausalität\n",
    "\n",
    "Ein gängiger Fehler bei der Datenanalyse ist das Verwechseln von Korrelation und Kausalität.\n",
    "Hängen zwei Merkmale kausal voneinander ab, so ist das eine Merkmal Ursache für Auswirkungen auf das andere.\n",
    "\n",
    "Bei einer Korrelation ist dies nicht der Fall.\n",
    "\n",
    "Ein klassisches Beispiel ist die Anzahl an gegessenem Speiseeis und der Häufigkeit von von Sonnenbränden. In den Sommermonaten steigen beide Merkmale deutlich an. Trotzdem ist eher zweifelhaft, dass der Verzehr von Speiseeis Sonnenbrände verursacht ;)\n",
    "\n",
    "Bevor man von Korrelationen auf Kausalitäten schließt, sollte man beim leisesten Zweifel ExpertInnen des jeweiligen Faches konsultieren.\n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Manuelle Detailanalyse\n",
    "\n",
    "Um die entdeckten Ausreißer überprüfen und dann eiordnen zu können (\"sind sie in Ordnung oder nicht?\"), braucht es Details zu ihnen.\n",
    "\n",
    "Dafür stehen im folgenden 3 Code-Zellen bereit, welche du an deine Bedürfnisse anpassen kannst um die gewünsche Info zu bekommen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe des Datensatzes, sortiert nach einer Spalte\n",
    "# es werden dabei nur die ersten uns letzten 5 Zeilen angezeigt\n",
    "\n",
    "daten_normiert.sort_values('Erbwerbstätige (15-64)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Gemeinde mit Maximum- oder Minimum-Werten in \n",
    "# einer gegebenen Spalte.\n",
    "\n",
    "# Die Spalte kann beliebige ersetzt werden.\n",
    "# für Maxima nutze den Befehl: argmax()\n",
    "# und argmin() für Minima.\n",
    "\n",
    "daten_normiert.iloc[daten_normiert['Alter'].argmax()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe von Gemeinden mit bestimmtem Namen\n",
    "\n",
    "# Ausgabe der gesäuberten Rohdaten (Datensatz \"gemeindedaten\")\n",
    "# aber Suche in den normierten Daten (\"daten_normiert\").\n",
    "\n",
    "gemeindedaten[daten_normiert['Name']=='Graz']\n",
    "\n",
    "# Erklärung des Befehlsaufbaues:\n",
    "# anzuzeigender_Datensatz[zu_durchsuchender_Datensatz['zu_durchsuchende_spalte']=='zu_suchender_inhalt']\n",
    "\n",
    "# Klarerweise kann auch gemeindedaten[gemeindedaten['Einwohner']==67] gesucht werden.\n",
    "# oder gemeindedaten[gemeindedaten['Einwohner']>=50000] für alle Gemeinden über 50.000 Einwohner"
   ]
  },
  {
   "source": [
    "## Lessons learned\n",
    "\n",
    "Siehe Folien im Logbuch für eine Einordnung der Datenfehler und was man dagegen tun kann.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Datensatz verbessern\n",
    "\n",
    "Dementsprechend wollen wir jetzt unseren Datensatz verbessern, indem wir ihn um eindeutige IDs für die Gemeinden erweitern. So einen Datensatz findet man zum Beispiel auf der Webseite der [Statistik Austria](http://www.statistik.at/web_de/klassifikationen/regionale_gliederungen/gemeinden/index.html)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen des Datensatzes mit den Gemeindekennzahlen\n",
    "gemeindekennzahlen = pd.read_csv('gemliste_knz.csv', sep=';')\n",
    "\n",
    "# Visuelle Kontrolle des Inhaltes\n",
    "gemeindekennzahlen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sowie Kontrolle ob die Spalten korrekt erkannt worden sind\n",
    "gemeindekennzahlen.dtypes"
   ]
  },
  {
   "source": [
    "Inhalt und Datentypen scheinen zu passen.\n",
    "\n",
    "* *Status* beschreibt ob eine Gemeinde Stadtrang oder Marktrecht hat\n",
    "* *PLZ* und *weitere Polstleitzahlen* sind für uns nicht relevant.\n",
    "* *Gemeindekennziffer* und *Gemeindecode* unterscheiden sich nur für die Wiener Bezirke: hier ist die Gemeindekennziffer für alle Bezirke gleich, während der Code eindeutig ist (wie der nächste Code-Block zeigt). Für uns ist also der Code interessanter."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die 23 Wiener Gemeindebezirke sind beginnen mit 9xxxx,\n",
    "# sind also am Ende des Dataframes. Wir können sie daher,\n",
    "# analog zu head() mit tail() ausgeben.\n",
    "\n",
    "gemeindekennzahlen.tail(23)"
   ]
  },
  {
   "source": [
    "Nun können wir ein weitere Stärken von Pandas (und den DataFrames) ausnützen: das Verbinden von Datensätzen!\n",
    "\n",
    "Wir verbinden unseren Gemeindedatensatz (allerdings den normierten *daten_normiert*) mit dem frisch importierten *gemeindekennzahlen* über die Felder *Name* und *Gemeindename*.\n",
    "\n",
    "Der DataFrame-Befehl dazu wird mit *join* aufgerufen\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemeinden_norm_kennz = gemeindekennzahlen.join(daten_normiert.set_index('Name'), on='Gemeindename')\n",
    "\n",
    "gemeinden_norm_kennz.head()"
   ]
  },
  {
   "source": [
    "## Umgang mit Datenfehlern\n",
    "\n",
    "Nach wie vor haben wir das Problem, dass wir die fehlerhaften Zeilen der Doppelgemeinden im Datensatz haben.\n",
    "\n",
    "Dieses Problem ist durch den Befehl *join* sogar noch größer geworden, wie wir uns mit folgendem Befehl ansehen können."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe aller Zeilen im neuen Datensatz gemeinden_norm_kenz\n",
    "# in denen in der Spalte \"Gemeindename\" ein Eintrag aus der \n",
    "# Liste [\"Warth\", \"Mühldorf\", \"Krumbach\"] vorkommt.\n",
    "\n",
    "gemeinden_norm_kennz[gemeinden_norm_kennz.Gemeindename.isin([\"Warth\", \"Mühldorf\", \"Krumbach\"])]"
   ]
  },
  {
   "source": [
    "Statt der tatsächlichen 6 Gemeinden (je 3 mit gleichem Namen) haben wir durch die Verknüpfung mittels *join* eine Verdoppelung.\n",
    "\n",
    "Wie im Logbuch beschrieben, entscheiden wir uns dafür die wenigen (bekannt) fehlerhaften Zeilen zu löschen, denn wir wollen im nächsten Schritt Machine Learning einsetzen. Und diese Technik ist per se nicht komplett genau."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir erstellen eine Kopie unseres bisherigen Datensatzes\n",
    "# \"gemeinden_norm_kennz\" mit dem Namen \"gem_daten_sauber\".\n",
    "gem_daten_sauber = gemeinden_norm_kennz.copy()\n",
    "\n",
    "\n",
    "# Finde alle Zeilen, wo der Inhalte von Spalte \"Gemeindename\" in der Liste\n",
    "# [\"Warth\", \"Mühldorf\", \"Krumbach\"] ist\n",
    "x = gem_daten_sauber.Gemeindename.isin([\"Warth\", \"Mühldorf\", \"Krumbach\"])\n",
    "\n",
    "# ~x ist das Inverse von x. Also alle Zeilen die NICHT in x\n",
    "# (also unsere 3 Gemeinden) sind.\n",
    "# Und nur diese Zeilen wollen wir im sauberen Datensatz gespeichert haben\n",
    "\n",
    "gem_daten_sauber = gem_daten_sauber[~x]\n",
    "\n",
    "gem_daten_sauber.shape"
   ]
  },
  {
   "source": [
    "# Machine Learning\n",
    "\n",
    "### Bundesland hinzufügen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idee: ML für Bundesländer: Gemeindekennzahl bzw Gemeindecode ignorieren, \"Bundaesland\" feld erstellen mit erster Ziffer (1-9).\n",
    "#Oder ist es besser, Kategorien zu erstellen? Zahlen 1-9 könnten als numerische Interpretation falsch verwendet werden.\n",
    "\n",
    "gem_daten_sauber['Bundesland'] = gem_daten_sauber['Gemeindekennziffer'].astype(str).str[0]\n",
    "gem_daten_sauber['Bundesland'] = gem_daten_sauber['Bundesland'].astype(int)\n",
    "\n",
    "gem_daten_sauber.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_daten_sauber.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_bundesland = {1:'Burgenland', 2:'Kärnten', 3:'Niederösterreich', 4:'Oberösterreich',\n",
    "                5:'Salzburg', 6:'Steiermark', 7:'Tirol', 8:'Vorarlberg', 9:'Wien'}\n",
    "gem_daten_sauber['Bundesland'].replace(d_bundesland, inplace=True)"
   ]
  },
  {
   "source": [
    "### Urbanisierungsgrad hinzufügen\n",
    "\n",
    "Quelle: [Statistik Austria](https://www.statistik.at/web_de/klassifikationen/regionale_gliederungen/stadt_land/index.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbanisierungsgrad = pd.read_csv('gemeinden_urbanisierungsgrad.csv', sep=';')\n",
    "\n",
    "urbanisierungsgrad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_daten_sauber = gem_daten_sauber.join(urbanisierungsgrad.set_index('GKZ'), on='Gemeindekennziffer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_daten_sauber.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLZ, Weitere PLZ, TXT löschen und CODE auf Urbanisierungsgrad ändern\n",
    "# brauchen wir Gemeindecode?\n",
    "# Die Werte von Urbanisierungsgrad könnte ich noch auf Text ändern .\n",
    "gem_daten_sauber.drop(columns=['PLZ des Gem.Amtes', 'weitere Postleitzahlen', 'TXT'], inplace=True)\n",
    "gem_daten_sauber.rename(columns= {'CODE' : 'Urbanisierungsgrad'}, inplace=True)\n",
    "d_urbanisierungsgrad = {1:'Hoch', 2:'Mittel', 3:'Niedrig'}\n",
    "gem_daten_sauber['Urbanisierungsgrad'].replace(d_urbanisierungsgrad, inplace=True)\n",
    "gem_daten_sauber.head()"
   ]
  },
  {
   "source": [
    "Erklärtext für holdout set\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten ausschließen damit man sie ausschließlich nur zum Schätzen benutzt:\n",
    "ml_datensatz = gem_daten_sauber.sample(frac=0.98, random_state=101)\n",
    "ungesehene_daten = gem_daten_sauber.drop(ml_datensatz.index)\n",
    "\n",
    "ml_datensatz.reset_index(drop=True, inplace=True)\n",
    "ungesehene_daten.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('Daten für die Modellierung: ' + str(ml_datensatz.shape))\n",
    "print('Ungesehene Daten für Schätzungen: ' + str(ungesehene_daten.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_datensatz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ich sollte nicht vergessen das am ende nochmal aufzurufen, damit man die predictions mit den eigentlichen werten vergleichen kann\n",
    "ungesehene_daten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "exp = setup(data=ml_datensatz, target='Urbanisierungsgrad', ignore_features=['Gemeindekennziffer', 'Gemeindename', 'Gemeindecode', 'Einwohner', 'Arbeitsstätten'], silent=True, session_id=101, train_size=0.70)\n",
    "\n",
    "# weitere optionen: ignore_low_variance, group_features, bin_numeric_features, group_features, transformation, normalize\n",
    "#    ensemble_model auch eine option? stack_models auch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best = compare_models(fold=3, exclude=['catboost', 'xgboost', 'lightgbm'])\n",
    "\n",
    "#hoffentlich funktioniert das..\n",
    "best = compare_models(fold=3, exclude=['lightgbm'])"
   ]
  },
  {
   "source": [
    "selected_model = create_model('rf', fold=3)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = tune_model(selected_model, fold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision boundary zu visualisieren\n",
    "plot_model(tuned_model, plot='confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fehler bei der Klassifizierung von den unterschiedlichen Urbanisierungsgraden\n",
    "plot_model(tuned_model, plot='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_model, plot='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_hoch = gem_daten_sauber[gem_daten_sauber['Urbanisierungsgrad'] == 'Hoch']\n",
    "urban_hoch.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpret_model(tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = finalize_model(tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geschaetzte_daten = predict_model(final_model, data=ungesehene_daten)\n",
    "geschaetzte_daten.head(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "\n",
    "\n",
    "___\n",
    "\n",
    "# E N D E \n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da776311d08bb511bbc2463cac11bf655b038c6f06bc1e299f5acf29978e4461"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}