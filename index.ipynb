{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "with open(\"alle_gemeinden.csv\") as f:\r\n",
    "    content = f.read()\r\n",
    "\r\n",
    "content = content.replace('\",\"','##@#!')    #To prevent deleting required commas\r\n",
    "content = content.replace(',','.')\r\n",
    "content = content.replace('##@#!','\",\"')\r\n",
    "\r\n",
    "with open(\"gemeinden.csv\", \"w\") as f:\r\n",
    "    content = f.write(content)\r\n",
    "\r\n",
    "dataset = pd.read_csv('gemeinden.csv', sep=';', na_values=[\"-\"])\r\n",
    "\r\n",
    "\r\n",
    "#dataset.head(100)\r\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.dtypes)\r\n",
    "\r\n",
    "# überprüfe ob Datensatz vollständig ist\r\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemeindeliste aus Statistik.at \r\n",
    "# Habe ersten 2 Zeilen (und die letzte Zeile) aus dem Datensatz löschen müssen weil es Text war... \r\n",
    "# gibt es eine bessere Methode als manuell löschen?\r\n",
    "dataset2 = pd.read_csv('gemliste_knz_edited.csv', sep=';')\r\n",
    "\r\n",
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = dataset2.join(dataset.set_index('Name'), on='Gemeindename')\r\n",
    "\r\n",
    "dataset3.head(2123)\r\n",
    "\r\n",
    "#PROBLEM: WIEN Namen sind anders\r\n",
    "# provisorische Lösung: ich bearbeite die Gemeindenamen im csv ... geht es auch anders?\r\n",
    "# habe dafür edited file benutzt\r\n",
    "# original ist auch da (gemliste_knz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_norm = dataset.copy()\r\n",
    "df_norm = dataset3.copy()\r\n",
    "df_norm[\"Arbeitsstätten\"] = df_norm[\"Arbeitsstätten\"]/df_norm[\"Einwohner\"]\r\n",
    "df_norm[\"Beschäftigte\"] = df_norm[\"Beschäftigte\"]/df_norm[\"Einwohner\"]\r\n",
    "df_norm[\"Erbwerbstätige (15-64)\"] = df_norm[\"Erbwerbstätige (15-64)\"]/df_norm[\"Einwohner\"]\r\n",
    "df_norm[\"Anzahl an Ehepaaren\"] = df_norm[\"Anzahl an Ehepaaren\"]/df_norm[\"Einwohner\"]\r\n",
    "\r\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Einwohner\", \"Arbeitsstätten\", \"Beschäftigte\", \"Alter\", \"Einkommen\", \"Erbwerbstätige (15-64)\", \"Grundstückspreise\", \"Anzahl an Ehepaaren\", \"Anzahl der Kinder\"]\n",
    "#ft_plot = sns.pairplot(dataset[features])\n",
    "\n",
    "#ft_plot = sns.pairplot(df_norm)\n",
    "ft_plot = sns.pairplot(df_norm[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zum Ansehen von interessanten Sachen\r\n",
    "# spalte=\"Anzahl an Ehepaaren\" ## Warth df_norm.iloc[11] hat 368 Ehepaare bei 171 Einwohnern\r\n",
    "# spalte=\"Beschäftigte\" ## Innere Stadt Wien hat 10x so viele Beschäftigte wie Einwohner\r\n",
    "\r\n",
    "spalte=\"Beschäftigte\"\r\n",
    "\r\n",
    "print(\"ABSOLUT\")\r\n",
    "print(dataset.loc[dataset[spalte] == dataset[spalte].max()])\r\n",
    "\r\n",
    "\r\n",
    "print(\" \")\r\n",
    "print(\"RELATIV\")\r\n",
    "df_norm.loc[df_norm[spalte] == df_norm[spalte].max()]\r\n",
    "\r\n",
    "#dataset.iloc[11]\r\n",
    "#df_norm.iloc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas profiling\r\n",
    "from pandas_profiling import ProfileReport\r\n",
    "#profile = ProfileReport(dataset, title='Pandas Profiling Report', explorative=True)\r\n",
    "\r\n",
    "#Interessante Warnung beim normierten Datensatz: \"Highly skewed\"\r\n",
    "profile = ProfileReport(df_norm, title='Pandas Profiling Report', explorative=True)\r\n",
    "#profile.to_file(\"pandas_report.html\")\r\n",
    "#profile.to_notebook_iframe()\r\n",
    "\r\n",
    "#PROBLEM: ValueError: Produced output is too large and cannot be displayed. Consider saving it to a file.\r\n",
    "# Wie kann man das vermeiden? Kennzahl löschen/ignorieren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweetviz ist vielleicht ein cooler Zusatz für die Datenanalyse. Manches wird einfacher und übersichtlicher gezeigt.\r\n",
    "# Man kann auch zwei verschiedene Variablen miteinander vergleichen, oder ein \"target\" haben, ähnlich wie \"groupby\" von tableone.\r\n",
    "import sweetviz as sv\r\n",
    "\r\n",
    "my_report = sv.analyze(df_norm)\r\n",
    "#my_report = sv.analyze(df_norm, target_feat='Beschäftigte')\r\n",
    "\r\n",
    "# mit compare_intra kann man z.B kategorische werte miteinander vergleichen\r\n",
    "# geht z.B mim medizin datensatz(ist hier derzeit nicht verfügbar..  aber man kann es lokal oder wo anders probieren):\r\n",
    "#my_report = sv.compare_intra(hd_df, hd_df['sex'] == 'male', ['Male', 'Female'])\r\n",
    "\r\n",
    "my_report.show_notebook()\r\n",
    "\r\n",
    "#noch ein vorteil: wird viel schneller ausgeführt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Als Funktion umschreiben\r\n",
    "def profile_hilfestellung(pandas_profile):\r\n",
    "    import json\r\n",
    "    from IPython.core.display import HTML\r\n",
    "\r\n",
    "    # Profile in JSON umwandeln\r\n",
    "    #json_data = pandas_profile.to_json()\r\n",
    "    #pandas_profile.to_file(\"your_report.json\")\r\n",
    "\r\n",
    "    # JSON File importieren\r\n",
    "    with open('your_report.json') as f:\r\n",
    "        import_json_data = json.load(f)\r\n",
    "\r\n",
    "    display(HTML(\"<h2> Hilfreiche Links: </h2>\"))\r\n",
    "\r\n",
    "    display(HTML(\"<p style='font-size:15px'> <a href='https://wissenschafts-thurm.de/grundlagen-der-statistik-wie-unterscheidet-man-zwischen-nominal-ordinal-und-kardinalskala/' target='_blank'>Grundlagen: Nominal-, Ordinal- und Kardinalskala</a> </p>\"))\r\n",
    "\r\n",
    "    # Man kann überprüfen ob kategorische, numerische, bool Werte vorhanden sind oder nicht\r\n",
    "    if 'Categorical' in import_json_data['table']['types'].keys():\r\n",
    "        display(HTML(\"<p style='font-size:15px'> <a href='https://en.wikipedia.org/wiki/List_of_analyses_of_categorical_data' target='_blank'>Analyse kategorischer Daten</a> </p>\"))\r\n",
    "\r\n",
    "    if 'Numeric' in import_json_data['table']['types'].keys():\r\n",
    "        display(HTML(\"<p style='font-size:15px'> <a href='http://analytics.datengeschichten.at/doku.php?id=statistische_grundlagen' target='_blank'>Statistische Grundlagen</a> </p>\"))\r\n",
    "\r\n",
    "    # Schleife zum durchgehen von Werten und Infos pro Variable\r\n",
    "    skewness_found = False\r\n",
    "    missing_found = False\r\n",
    "\r\n",
    "\r\n",
    "    for key, value in import_json_data['variables'].items():\r\n",
    "        if value['n_missing'] != 0 and missing_found==False:\r\n",
    "            display(HTML(\"<p style='font-size:15px'> <a href='https://www.inwt-statistics.de/blog-artikel-lesen/fehlende-werte-verstehen-und-handhaben.html' target='_blank'>Was macht man mit fehlenden Werten?</p></a>\"))\r\n",
    "            missing_found = True\r\n",
    "        if 'skewness' in value and skewness_found==False:\r\n",
    "            display(HTML(\"<p style='font-size:15px'> <a href='https://matheguru.com/stochastik/schiefe-linksschief-rechtsschief-symmetrisch.html' target='_blank'>Was bedeutet eine Skewness von \" + str(value['skewness']) + \" bei \" + key + \"?</p></a>\"))\r\n",
    "            skewness_found = True\r\n",
    "\r\n",
    "    # Weitere allgemeine Links\r\n",
    "\r\n",
    "    display(HTML(\"<p style='font-size:15px'> <a href='https://www.data-to-viz.com' target='_blank'>Visualisierungen nach/für Merkmal</a> </p>\"))\r\n",
    "\r\n",
    "    display(HTML(\"<p style='font-size:15px'> <a href='https://www.youtube.com/watch?v=gP-Xx26p_kc' target='_blank'>Video zur Binomial- und Normalverteilung</a> </p>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "# Funktion ausprobieren\r\n",
    "profile_hilfestellung(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kurze Übersicht: will vermutlich den normierten Datensatz benutzen\r\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idee: ML für Bundesländer: Gemeindekennzahl bzw Gemeindecode ignorieren, \"Bundaesland\" feld erstellen mit erster Ziffer (1-9).\r\n",
    "#Oder ist es besser, Kategorien zu erstellen? Zahlen 1-9 könnten als numerische Interpretation falsch verwendet werden.\r\n",
    "\r\n",
    "df_norm['Bundesland'] = df_norm['Gemeindekennziffer'].astype(str).str[0]\r\n",
    "df_norm['Bundesland'] = df_norm['Bundesland'].astype(int)\r\n",
    "\r\n",
    "df_norm.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_bundesland = {1:'Burgenland', 2:'Kärnten', 3:'Niederösterreich', 4:'Oberösterreich',\r\n",
    "                5:'Salzburg', 6:'Steiermark', 7:'Tirol', 8:'Vorarlberg', 9:'Wien'}\r\n",
    "df_norm['Bundesland'].replace(d_bundesland, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\r\n",
    "exp = setup(data=df_norm, target='Bundesland', ignore_features=['Gemeindekennziffer', 'Gemeindename', 'Gemeindecode', 'PLZ des Gem.Amtes', 'weitere Postleitzahlen'], silent=True, session_id=101)\r\n",
    "\r\n",
    "# weitere optionen: ignore_low_variance, group_features, bin_numeric_features, group_features, transformation, normalize\r\n",
    "#    ensemble_model auch eine option? stack_models auch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#877.2s ... weniger folds? folds auf 3 probieren\n",
    "\n",
    "#best = compare_models(fold=3, exclude=['catboost', 'xgboost', 'lightgbm'])\n",
    "\n",
    "best = compare_models(fold=3, exclude=['lightgbm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = create_model('rf', fold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = tune_model(selected_model, fold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_model(tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_holdout = predict_model(tuned_model)\r\n",
    "pred_holdout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "757a07231266d6fd5528e409d0ea65fbf80bcee06be4e81fbe733c69e7de4acd"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}